
<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Causal Machine Learning - AI4Science101</title>
    <link rel="stylesheet" href="/assets/css/app.css">
    <link rel="shortcut icon" type="image/png"
           href="/favicon.png" 
    />
    <script defer src="https://use.fontawesome.com/releases/v5.3.1/js/all.js"></script>
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Causal Machine Learning | AI4Science101</title>
<meta name="generator" content="Jekyll v4.3.2" />
<meta property="og:title" content="Causal Machine Learning" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="AI for Science 101" />
<meta property="og:description" content="AI for Science 101" />
<link rel="canonical" href="http://localhost:4000/blogs/causal_machine_learning/" />
<meta property="og:url" content="http://localhost:4000/blogs/causal_machine_learning/" />
<meta property="og:site_name" content="AI4Science101" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Causal Machine Learning" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","description":"AI for Science 101","headline":"Causal Machine Learning","url":"http://localhost:4000/blogs/causal_machine_learning/"}</script>
<!-- End Jekyll SEO tag -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-183522810-1"></script>
<script>
  window['ga-disable-UA-183522810-1'] = window.doNotTrack === "1" || navigator.doNotTrack === "1" || navigator.doNotTrack === "yes" || navigator.msDoNotTrack === "1";
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-183522810-1');
</script><!-- head scripts --></head>

  <body>
    
<nav class="navbar is-primary" >
    <div class="container">
        <div class="navbar-brand">
            <a class="navbar-brand" href="/">
            <span><img src="/logonav.png" alt="Logo" style="height: auto; width: auto; max-height: 45px; max-width: 250px;"></span>
            </a>
            <a role="button" class="navbar-burger burger" aria-label="menu" aria-expanded="false" data-target="navMenu">
                <span aria-hidden="true"></span>
                <span aria-hidden="true"></span>
                <span aria-hidden="true"></span>
            </a>
        </div>
        <div class="navbar-menu" id="navMenu">
            <div class="navbar-end">
                
                
                    
                    <a href="/" class="navbar-item ">Home</a>
                    
                
                    
                    <div class="navbar-item has-dropdown is-hoverable">
                        <a href="/blogs/" class="navbar-link ">Blogs</a>
                        <div class="navbar-dropdown">
                            
                            <a href="/blogs/announcement/" class="navbar-item ">Announcement</a>
                            
                            <a href="/blogs/ai_for_science_science/" class="navbar-item ">AI for Scientific Discovery</a>
                            
                            <a href="/blogs/ai_for_science_ai/" class="navbar-item ">Scientific Discovery in the era of AI</a>
                            
                            <a href="/blogs/molecular_simulation/" class="navbar-item ">Molecular Simulation</a>
                            
                            <a href="/blogs/gaussian_processes/" class="navbar-item ">Gaussian Processes</a>
                            
                            <a href="/blogs/causal_machine_learning/" class="navbar-item is-active">Causal Machine Learning</a>
                            
                            <a href="/blogs/statistical_learning_theory/" class="navbar-item ">Statistical Learning Theory</a>
                            
                            <a href="/blogs/optimization/" class="navbar-item ">Optimization</a>
                            
                            <a href="/blogs/graph_machine_learning/" class="navbar-item ">Graph Machine Learning</a>
                            
                            <a href="/blogs/knowledge_base/" class="navbar-item ">Knowledge Base</a>
                            
                        </div>
                    </div>
                    
                
                    
                    <a href="/resources/" class="navbar-item ">Resources</a>
                    
                
                
            </div>

        </div>
    </div>
</nav>

    
    


    <section class="section">
        <div class="container">
            <div class="columns">
                
                <div class="column is-4-desktop is-4-tablet">
                    

<aside class="menu">

</aside>
                </div>
                
                <div class="column is-8">
                    
                    
                    
                    
    
    

<div class="contents">
    <div class="menu">
        <p class="menu-label">Causal Machine Learning</p>
        <ul class="menu-list">
  <li><a href="#learning-causations-from-observational-data">Learning Causations from Observational Data</a></li>
  <li><a href="#what-is-causal-representation-learning">What is causal representation learning?</a></li>
  <li><a href="#causal-discovery-methods-and-applications">Causal Discovery: Methods and Applications</a></li>
  <li><a href="#applications-in-science">Applications in Science</a>
    <ul>
      <li><a href="#a-quick-example">A quick example</a></li>
      <li><a href="#benchmarks">Benchmarks</a></li>
    </ul>
  </li>
  <li><a href="#learning-resources">Learning Resources</a></li>
</ul>
    </div>
</div>




<div class="content">
    <script type="text/javascript" async="" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<h2 id="learning-causations-from-observational-data">Learning Causations from Observational Data</h2>

<p>Identifying the causal relationships that govern various observed phenomena is an essential objective across diverse scientific disciplines, as it helps researchers understand the underlying mechanisms and facilitate principled analysis. For instance, in medical research, scientists strive to uncover the causal links between environmental factors, genetic predispositions, and disease incidence to develop effective treatments and prevention strategies. In this chapter, we briefly introduce computational methods for learning causation from observational data. Because of the relatively high cost of experimental interventions in real-world scenarios, it is desirable to have principled methods to benefit from causality given only observational data. We start with an overview of causal representation learning and causal discovery. Then we describe some instances of applications of causality in science. Finally, we introduce an open-source tool for causal discovery with a quick example of usage. All materials only serve as an informal and incomplete introduction to those who would like to take a glance at the topic, instead of a part of a formal survey.</p>

<h2 id="what-is-causal-representation-learning">What is causal representation learning?</h2>
<p>Causal representation learning connects the fields of causality and deep learning. Over the past decade, deep learning has become a key technology in AI fields such as computer vision and natural language processing and has also been used to empower various industries such as robotics, autonomous driving, human-computer interaction systems, virtual reality, pharmaceuticals, and smart cities. This method uses neural networks to transform unstructured data such as images and text into representations that can be processed by machines and solve downstream tasks like recognition and understanding. The aim of representation learning is to reduce the dimensionality of high-dimensional raw data to low-dimensional features while preserving information and removing noise.</p>

<p>As scientists, the pursuit of knowledge is at the forefront of our work, and there is a particular fascination with uncovering causal relationships that underlie observed phenomena. With the advent of black-box algorithms that can make accurate predictions without revealing the underlying causal mechanisms, it is becoming increasingly important to discover and understand the causal relationships that drive these predictions. Researchers are interested in developing interpretable learning models that can identify causal relationships between inputs and outputs, enabling greater transparency and control over the decision-making process.</p>

<p>However, the representations learned by scaling up data and model size often only encode, compress, or memorize data. These representations lack higher-order semantic concepts that can be used by machines for logical reasoning and planning and do not have the adaptability and robustness to solve problems in new environments like humans. Consequently, making deep learning capable of conscious reasoning, thinking, and judgment like humans is a crucial challenge for the next generation of AI. On the other hand, causal models provide a systematic and statistical approach to causal reasoning and thinking. Yet, these models typically only handle structured data and cannot process the high-dimensional raw data encountered in real-life scenarios such as images. The fusion of representation learning and causal models, which transforms raw data like images into structured variables usable by causal models, allows AI to reason and think consciously like humans, making it the primary goal of the emerging field of causal representation learning. Solving this problem would enable us to combine causal inference with machine learning and build the next generation of flexible and trustworthy AI.</p>

<center><img src="/img/Causal_Machine_Learning/latent.png" width="40%" height="40%" /></center>
<center>Figure 1: An example of the causal hidden variables (e.g., {L1, L2, L3, L4}).</center>
<p><br /></p>

<p>In causal representation learning, we typically assume that data is generated by causal hidden variables that are related to each other and satisfy certain conditions of a structural causal model (SCM) through nonlinear mapping. If the causal hidden variables and the SCM between them can be learned from the original data, we can estimate the data distribution after intervening on these variables, or infer the counterfactual results of a specified data point, such as generating data that does not exist in the real world by re-combining the causal hidden variables, or answering questions that require explicit reasoning such as “Why” or “What if”. It is worth noting that causal representation learning is closely related to causal discovery. On the one hand, causal representation learning is a special case of the causal discovery problem with many confounders. On the other hand, it is extremely difficult to learn the structural causal model in the entire hidden variable space without domain knowledge. Therefore, the assumptions commonly used in causal discovery, such as Sparsity, Minimal Change Principle, and Independent Causal Mechanism, can often serve as domain knowledge and inductive bias for causal representation learning.</p>

<h2 id="causal-discovery-methods-and-applications">Causal Discovery: Methods and Applications</h2>

<p>Discovering and obtaining causal relationships from data has played a crucial role in various disciplines as a fundamental data analysis method in the past few decades. Almost all sciences are about identifying causal relationships and the laws or regularities that govern them. Since the beginning of modern science in the 17th century, there have been two methods for discovering causal relationships: (1) manipulating and changing certain characteristics in a system and observing whether other characteristics change, and (2) observing changes in system characteristics without manipulation. These two methods flourished in the 17th century and were intertwined with each other, as disccused in [1]: “Ivan Johannes Stal-Tolcheli manipulated the angle and shape of a tube containing mercury, but the height of the mercury did not change. Pascal lifted the pressure gauge designed by Tolcheli to a mountain to prove that the height of the mercury did indeed change with altitude. Galileo determined (qualitatively) the orbit of the moon around Europa by observing time series. Kepler derived his three laws of planetary motion from planetary observations. And Newton laid the foundations of modern physics with the law of gravitation, derived from observations of the solar system and a single experiment. Modern molecular biology is an experimental subject, but the foundation of biology, in Darwin’s “Origin of Species”, is based on only one experiment, i.e., the seed drift.”</p>

<center><img src="/img/Causal_Machine_Learning/causalgraph.png" width="40%" height="40%" /></center>
<center>Figure 2: An example of the causal graph.</center>
<p><br /></p>

<p>Classic causal discovery methods are usually used to find causal relationships between observed variables, which can be roughly divided into two categories. At the end of the 1980s and the beginning of the 1990s, it was noticed that, under appropriate assumptions, the latent causal structure could be recovered from the conditional independence relationships between variables in a Markov equivalence class [2]. This has led to constraint-based methods that use conditional independence tests and discrete searches for causal discovery. The resulting equivalence classes may contain multiple directed acyclic graphs (DAGs, or other graph objects that represent causal structures) that share the same conditional independence relationships. The required assumptions include the causal Markov condition and the faithfulness assumption, which establish a correspondence between the d-separation properties in the causal graph and the statistical independence properties in the data. On the contrary, score-based methods [3, 4] are not based on statistical tests, but search for equivalence classes with the highest scores under certain scoring criteria, such as the Bayesian information criterion [5] and the generalized score [6]. Moreover, exact score-based methods [7] can also recover the causal structure in a divide-and-conquer manner.</p>

<p>Another set of methods is based on functional causal model (FCM), which represent the effect as its direct cause and the corresponding independent noise. It has been shown that, with appropriate constraints on the model classes, the direction of the causal effet can be identified. Specifically, when the FCM is estimated in the correct causal direction, the estimated noise term is independent of the hypothesized cause, of which the phenomenon does not hold in the inverse direction. Identifiable causal models include LiNGAM [8], additive noise causal model [9, 10], post-nonlinear causal model [11, 12]. However, it is noteworthy that if the function space of the functional causal model is not constrained, the causal direction cannot be identified [13].</p>

<p>The methods presented above have been extended to more general scenarios. For example, LiNGAM has been extended to causal graphs with loops [14] and in the presence of potential confounders [15]. The specific and shared causal relation modeling [16], which is based on LiNGAM, can provide not only global causal structures but also individualized causal knowledge and clustering based on causal relationships. Also, it is shown that causal models (including causal direction) are possible to identify even in the presence of selection bias [17].</p>

<p>Currently, methods for causal discovery focus on finding causal relationships between observed variables, but in real-world problems, many relevant features may not be observed, and some observed variables may not be latent causal variables. For example, we cannot directly treat image pixels as causal variables. Therefore, as mentioned in the first part, we want to learn the latent causal representation from the measured high-dimensional variables and the causal relationships between them, which is essential in both general artificial intelligence and scientific fields. For example, in AI, we want to automatically extract underlying low-dimensional causal variables or concepts from high-dimensional video sequences, which are crucial for video understanding, thus promoting downstream prediction or decision-making tasks. In neuroscience, one key problem is how to identify and hierarchically cluster latent brain functional areas and discover information flow from the thousands of voxels measured in fMRI recordings. Recent advances introduce methods for recovering hidden causal variables in a principled manner [18]. Besides, since causal discovery is a special case of Independent Component Analysis (ICA), recent breakthroughs in identifiable nonlinear ICA without auxiliary variables also shed light on the recovery of the hidden causal structures with general nonlinear causal relations [19].</p>

<h2 id="applications-in-science">Applications in Science</h2>

<p>In this section, we present several quick examples of the application of causality in science. Since we focus more on computational methods instead of experimental interventions. we just include causal discovery methods on observational data.</p>

<center><img src="/img/Causal_Machine_Learning/sachs.png" width="40%" height="40%" /></center>
<center>Figure 3: Causal protein-signaling networks (Sachs) [20].</center>
<p><br /></p>

<p>One of the most significant applications of causal discovery in science is in the field of genetics. For example, researchers can use causal discovery techniques to identify genes that play a role in the development of complex diseases such as cancer, heart disease, and mental illness. By understanding the causal relationships between genes and disease, researchers can prioritize potential therapies and predict their efficacy, leading to faster and more effective drug development.</p>

<center><img src="/img/Causal_Machine_Learning/alz.png" width="40%" height="40%" /></center>
<center>Figure 4: Discovered causal structure among demographic variables, biomarkers, and genetics on data from Alzheimer’s Disease Neuroimaging Initiative (ADNI) database  [21].</center>
<p><br /></p>

<p>Another example of causal discovery in science is in the field of pharmacology. Researchers can use it to study the relationships between drugs and their side effects. By understanding these causal relationships, they can predict the likelihood of side effects and design safer and more effective drugs.</p>

<p>In the field of physics, causal discovery can be used to study complex systems such as climate change. For example, scientists can use it to identify the causal relationships between greenhouse gas emissions, deforestation, and global temperatures. This information can be used to make predictions about future climate patterns and inform policy decisions aimed at mitigating the effects of climate change.</p>

<p>In the social sciences, causal discovery has applications in fields such as psychology, sociology, and economics. For example, researchers can use causal discovery techniques to study the relationships between variables such as personality traits, social norms, and economic variables. By understanding these causal relationships, they can gain insights into human behavior and design more effective policies and interventions.</p>

<p>In conclusion, the applications of causal discovery in science are wide-ranging and have the potential to revolutionize our understanding of complex systems and processes. By uncovering the causal relationships between variables, researchers can gain a deeper understanding of the factors that drive these systems and design more effective tools and technologies. The common pipeline for applying causal discovery in real-world problems [1] could be summarized as follows:</p>

<ul>
  <li>Check the data distribution to have a basic understanding of the distribution type and functional relations.</li>
  <li>Check whether the preprocessing has distorted the distributions or not. For example, high pass filtering in fMRI software may eliminate the non-Gaussianity in variables.</li>
  <li>Check if missing values, selection bias, latent confounders, or other challenges should be considered in the application. If so, specific algorithms could be adopted. Here is a non-exhaustive list of method choices for reference. The implementations of these can be found in <a href="https://causal-learn.readthedocs.io/en/latest/index.html"><strong>causal-learn</strong></a>
    <ul>
      <li>Causal discovery from nonstationary and/or heterogeneous data [22].</li>
      <li>Causal discovery for specific functional model [12, 8, 9].</li>
      <li>Causal discovery with confounders (latent variables) and selection bias [23, 18].</li>
      <li>Causal discovery with missing values [24].</li>
      <li>Causal discovery with discrete or mixed-type data [6].</li>
      <li>Causal discovery with (almost) nonparametric model [25, 6].</li>
    </ul>
  </li>
  <li>Based on the observed distribution type and functional relations between variables, choose the appropriate causal discovery/causal representation learning method.</li>
  <li>Make use of the known causal relations, such as those from experiments or domain experts. These relations can serve as the ground truth to test the reasonableness of the result. Besides, one can also use this background knowledge as a constraint to both speed up the algorithm and improve the quality.</li>
  <li>If possible, try to find the best practice by testing on the synthetic data first.</li>
</ul>

<p>Besides learning on observational data, causal inference based on experimental data is also a powerful tool used in scientific research to determine the causal relationships between variables in a system. In experimental settings, researchers deliberately manipulate one or more variables and observe the resulting changes in other variables, allowing them to make causal inferences about the relationship between the manipulated variable and the other variables in the system. This approach is widely used in many fields of science, from biology to social sciences, to establish cause-and-effect relationships between variables. For example, in medicine, clinical trials involve randomly assigning participants to different treatments and observing the resulting changes in health outcomes, allowing researchers to make inferences about the causal effects of the treatments. In social sciences, randomized control trials are used to test the effectiveness of interventions aimed at improving various outcomes, such as education or employment.</p>

<p>At the same time, when manipulation of variables is not possible, counterfactual reasoning allows researchers to compare outcomes from different hypothetical scenarios and infer the causal effects of a variable on another variable. One example of counterfactual reasoning in science is in epidemiology, where researchers may investigate the impact of exposure to a certain risk factor (such as smoking) on a health outcome (such as lung cancer) by comparing the outcomes of individuals who were exposed to the risk factor to those who were not exposed (a counterfactual scenario). In physics, counterfactual reasoning has been used to explore the nature of quantum mechanics by considering the outcomes of experiments that were not actually performed. Counterfactual reasoning is also used in social sciences, such as in policy evaluation, where researchers may use counterfactuals to estimate the impact of an intervention or policy by comparing the outcomes of a group that received the intervention to those of a group that did not.</p>

<h1 id="tool-for-causal-discovery-causal-learn">Tool for causal discovery: causal-learn</h1>

<p>Causal-learn is a causal discovery platform led by Prof. Kun Zhang at Carnegie Mellon University (CMU) and developed by multiple teams. Causal-learn is implemented in Python and is based on CMU’s Tetrad causal discovery platform developed in Java, but with additional algorithms and features. It includes classic algorithms and APIs for causal discovery and modular code for researchers to implement their own algorithms. All modules in causal-learn are implemented in Python, avoiding the dependence on R/Java of traditional causal discovery libraries and providing convenience for Python developers. Causal-learn supports:</p>

<ul>
  <li>Constrained-based causal discovery methods;</li>
  <li>Score-based causal discovery methods;</li>
  <li>Causal discovery methods based on constrained functional causal models;</li>
  <li>Hidden causal representation learning;</li>
  <li>Permutation-based causal discovery methods;</li>
  <li>Granger causal analysis;</li>
  <li>Multiple independent basic modules, such as independence tests, scoring functions, graph operations, and evaluation metrics;</li>
  <li>More recent causal discovery algorithms such as gradient-based methods.</li>
</ul>

<p>Besides classical algorithms (e.g., PC and GES) with state-of-the-art implementation, below is a non-exclusive list of how specific types of problems or practical challenges can be addressed by methods in causal-learn. Detailed instruction and usage examples can be found at the documentation of <a href="https://causal-learn.readthedocs.io/en/latest/index.html">causal-learn</a>.</p>

<ul>
  <li>Causal discovery from nonstationary and/or heterogeneous data: CD-NOD [22].</li>
  <li>Causal discovery for specific functional model: post-nonlinear models (PNL) [12], linear, non-Gaussian acyclic models (LiNGAM) [8], and additive noise models (ANM) [9].</li>
  <li>Causal discovery with confounders (latent variables) and selection bias: fast causal inference (FCI) [23] and Generalized Independence Noise condition-based method (GIN) [18].</li>
  <li>Causal discovery with missing values: missing-value PC (MVPC) [24].</li>
  <li>Causal discovery with discrete or mixed-type data: Generalized Score [6].</li>
  <li>Causal discovery with (almost) nonparametric model: kernel-based conditional independence test (KCI) [25] and Generalized Score [6].</li>
</ul>

<p>Causal-learn is designed to modularize the code as much as possible to simplify the development difficulty for researchers. At the same time, by providing concise and efficient code interfaces, users from different fields can easily apply causal discovery algorithms. The whole platform is based on Python, and users no longer need to rely on Java or R environments to fully enjoy the convenience of Python development and use. At the same time, causal-learn provides a simple installation method, and one line of code can deploy the most classic and comprehensive causal recommendation algorithms in the user’s project.</p>

<p>Besides, causal-learn includes official implementations of many classic algorithms and their extensions, such as PC, PNL, LiNGAM, etc. The main authors of these “milestone” algorithms in the field of causal discovery are in the leadership team of causal-learn to guide the direction of platform construction. Therefore, causal-learn provides the most “official” algorithm implementation. By familiarizing with the related codes, users can quickly master the classic algorithms of causal discovery, so as to grasp the overall development of the field and provide inspiration for relevant research.</p>

<p>Moreover, causal-learn has a stable development and maintenance team, and the research team behind it continues to output the latest work in the field of causal discovery. Therefore, users can keep abreast of the latest developments in the field by following the causal-learn algorithm platform, and applying the latest work to different scientific research and production projects in a timely manner.</p>

<h3 id="a-quick-example">A quick example</h3>

<p>Here we show a quick example of how to use causal-learn to perform causal discovery on observational data. The following example is the PC algorithm:</p>

<!-- \definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=Python,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
} -->

<pre><code class="language-python:">from causallearn.search.ConstraintBased.PC import pc

cg = pc(data)

# visualization using pydot

cg.draw_pydot_graph()

# or save the graph

from causallearn.utils.GraphUtils import GraphUtils

pyd = GraphUtils.to_pydot(cg.G)
pyd.write_png('simple_test.png')

# visualization using networkx

# cg.to_nx_graph()

# cg.draw_nx_graph(skel=False)
</code></pre>

<p>Then we can obtain the causal graph corresponding to the causal process hidden underlying the observational data. More examples can be found in the <a href="https://causal-learn.readthedocs.io/en/latest/index.html&gt;}{&lt;https://causal-learn.readthedocs.io/en/latest/index.html">documentation</a>.</p>

<h3 id="benchmarks">Benchmarks</h3>

<p>Here we show a list of benchmark datasets for real-world problems and tasks that might be of interest to readers:</p>

<ul>
  <li><strong>Infant Health and Development Program (IHDP) data:</strong> <a href="https://www.tandfonline.com/doi/suppl/10.1198/jcgs.2010.08162?scroll=top">https://www.tandfonline.com/doi/suppl/10.1198/jcgs.2010.08162?scroll=top</a></li>
  <li><strong>Churn for bank customers dataset:</strong><a href="https://www.kaggle.com/mathchi/churn-for-bank-customers/">https://www.kaggle.com/mathchi/churn-for-bank-customers/</a></li>
  <li><strong>Teleco customer churn</strong> <a href="https://www.kaggle.com/blastchar/telco-customer-churn">https://www.kaggle.com/blastchar/telco-customer-churn</a></li>
  <li><strong>Abalone data:</strong> <a href="https://archive.ics.uci.edu/ml/datasets/abalone">https://archive.ics.uci.edu/ml/datasets/abalone</a></li>
  <li><strong>Boston housing data:</strong> <a href="https://archive.ics.uci.edu/ml/machine-learning-databases/housing/">https://archive.ics.uci.edu/ml/machine-learning-databases/housing/</a></li>
  <li><strong>Sachs data:</strong> <a href="https://www.bnlearn.com/research/sachs05/index.html">https://www.bnlearn.com/research/sachs05/index.html</a></li>
</ul>

<h2 id="learning-resources">Learning Resources</h2>

<p>Of course, this chapter is just a glance at learning causation for science. If needed, readers are encouraged to explore other learning resources, e.g.,</p>

<ul>
  <li>Books:
    <ul>
      <li>Causation, Prediction, and Search [2].</li>
      <li>The Book of Why: the New Science of Cause and Effect [26].</li>
      <li>The Mind’s Arrows [27].</li>
      <li>Elements of Causal Inference: Foundations and Learning Algorithms [28].</li>
      <li>Causal Inference in Statistics: A Primer [29].</li>
      <li>Causal Inference for Statistics, Social, and Biomedical Sciences: An Introduction [30].</li>
    </ul>
  </li>
  <li>Online seminars:
    <ul>
      <li><a href="https://sites.google.com/view/ocis/home">Online Causal Inference Seminar</a>.</li>
      <li><a href="https://www.matej-zecevic.de/cdg/">Causality Discussion Group</a>.</li>
      <li><a href="https://sites.google.com/view/zhigao-guo/causality-seminar">Causality Seminar</a>.</li>
    </ul>
  </li>
</ul>

<h1 id="references">References</h1>

<p>[1] Clark Glymour, Kun Zhang, and Peter Spirtes. Review of causal discovery methods based on graphical models. Frontiers in genetics, 10:524, 2019.</p>

<p>[2] Peter Spirtes, Clark N Glymour, Richard Scheines, and David Heckerman. Causation, prediction, and search. MIT press, 2000.</p>

<p>[3] David Maxwell Chickering. Optimal structure identification with greedy search. Journal of machine learning research, 3(Nov):507–554, 2002.</p>

<p>[4] David Heckerman, Dan Geiger, and David M Chickering. Learning bayesian networks: The combination of knowledge and statistical data. Machine learning, 20:197–243, 1995.</p>

<p>[5] Gideon Schwarz. Estimating the dimension of a model. The annals of statistics, pages 461–464, 1978.</p>

<p>[6] Biwei Huang, Kun Zhang, Yizhu Lin, Bernhard Schölkopf, and Clark Glymour. Generalized score functions for causal discovery. In Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery &amp; data mining, pages 1551–1560, 2018.</p>

<p>[7] Ignavier Ng, Yujia Zheng, Jiji Zhang, and Kun Zhang. Reliable causal discovery with improved exact search and weaker assumptions. Advances in Neural Information Processing Systems, 34:20308–20320, 2021.</p>

<p>[8] Shohei Shimizu, Patrik O Hoyer, Aapo Hyvärinen, Antti Kerminen, and Michael Jordan. A linear non-Gaussian acyclic model for causal discovery. Journal of Machine Learning Research, 7(10), 2006.</p>

<p>[9] Patrik O Hoyer, Dominik Janzing, Joris M Mooij, Jonas Peters, Bernhard Schölkopf, et al. Nonlinear causal discovery with additive noise models. In NIPS, volume 21, pages 689–696. Citeseer, 2008.</p>

<p>[10] Kun Zhang and Aapo Hyvärinen. Causality discovery with additive disturbances: An information-theoretical perspective. In Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2009, Bled, Slovenia, September 7-11, 2009, Proceedings, Part II 20, pages 570–585. Springer, 2009.</p>

<p>[11] Kun Zhang and Lai-Wan Chan. Extensions of ica for causality discovery in the hong kong stock market. In Neural Information Processing: 13th International Conference, ICONIP 2006, Hong Kong, China, October 3-6, 2006. Proceedings, Part III 13, pages 400–409. Springer, 2006.</p>

<p>[12] K Zhang and A Hyvärinen. On the identifiability of the post-nonlinear causal model. In 25th Conference on Uncertainty in Artificial Intelligence (UAI 2009), pages 647–655. AUAI Press, 2009.</p>

<p>[13] Kun Zhang, Zhikun Wang, Jiji Zhang, and Bernhard Schölkopf. On estimation of functional causal models: general results and application to the post-nonlinear causal model. ACM Transactions on Intelligent Systems and Technology (TIST), 7(2):1–22, 2015.</p>

<p>[14] Gustavo Lacerda, Peter L Spirtes, Joseph Ramsey, and Patrik O Hoyer. Discovering cyclic causal models by independent components analysis. arXiv preprint arXiv:1206.3273, 2012.</p>

<p>[15] Patrik O Hoyer, Shohei Shimizu, Antti J Kerminen, and Markus Palviainen. Estimation of causal effects using linear non-Gaussian causal models with hidden variables. International Journal of Approximate Reasoning, 49(2):362–378, 2008.</p>

<p>[16] Biwei Huang, Kun Zhang, Pengtao Xie, Mingming Gong, Eric P Xing, and Clark Glymour. Specific and shared causal relation modeling and mechanism-based clustering. Advances in Neural Information Processing Systems, 32, 2019.</p>

<p>[17] Kun Zhang, Jiji Zhang, Biwei Huang, Bernhard Schölkopf, and Clark Glymour. On the identifiability and estimation of functional causal models in the presence of outcome-dependent selection. In UAI, 2016.</p>

<p>[18] Feng Xie, Ruichu Cai, Biwei Huang, Clark Glymour, Zhifeng Hao, and Kun Zhang. Generalized independent noise condition for estimating latent variable causal graphs. In NeurIPS, 2020.</p>

<p>[19] Yujia Zheng, Ignavier Ng, and Kun Zhang. On the identifiability of nonlinear ICA: Sparsity and beyond. In Advances in Neural Information Processing Systems, 2022.</p>

<p>[20] Karen Sachs, Omar Perez, Dana Pe’er, Douglas A Lauffenburger, and Garry P Nolan. Causal protein-signaling networks derived from multiparameter single-cell data. Science, 308(5721):523–529, 2005.</p>

<p>[21] Xinpeng Shen, Sisi Ma, Prashanthi Vemuri, and Gyorgy Simon. Challenges and opportunities with causal discovery algorithms: application to alzheimer’s pathophysiology. Scientific reports, 10(1):2975, 2020.</p>

<p>[22] Biwei Huang, Kun Zhang, Jiji Zhang, Joseph D Ramsey, Ruben Sanchez-Romero, Clark Glymour, and Bernhard Schölkopf. Causal discovery from heterogeneous/nonstationary data. J. Mach. Learn. Res., 21(89):1–53, 2020.</p>

<p>[23] Peter L Spirtes, Christopher Meek, and Thomas S Richardson. Causal inference in the presence of latent variables and selection bias. Uncertainty in Artificial Intelligence, 1995.</p>

<p>[24] Ruibo Tu, Cheng Zhang, Paul Ackermann, Karthika Mohan, Hedvig Kjellström, and Kun Zhang. Causal discovery in the presence of missing data. In The 22nd International Conference on Artificial Intelligence and Statistics, pages 1762–1770. PMLR, 2019.</p>

<p>[25] Kun Zhang, Jonas Peters, Dominik Janzing, and Bernhard Schölkopf. Kernel-based conditional independence test and application in causal discovery. arXiv preprint arXiv:1202.3775, 2012.</p>

<p>[26] Judea Pearl and Dana Mackenzie. The book of why: the new science of cause and effect. Basic books, 2018.</p>

<p>[27] Clark N Glymour. The mind’s arrows: Bayes nets and graphical causal models in psychology. MIT press, 2001.</p>

<p>[28] Jonas Peters, Dominik Janzing, and Bernhard Schölkopf. Elements of causal inference: foundations and learning algorithms. The MIT Press, 2017.</p>

<p>[29] Judea Pearl, Madelyn Glymour, and Nicholas P Jewell. Causal Inference in Statistics: A Primer. John Wiley &amp; Sons, 2016.</p>

<p>[30] Guido W Imbens and Donald B Rubin. Causal inference in statistics, social, and biomedical sciences. Cambridge University Press, 2015.</p>


</div>
                </div>
                
            </div>
        </div>
    </section>
    
        <!-- <footer class="footer">
    <div class="container">
        
        <div class="columns is-mobile">
            <div class="column is-8 has-text-left is-vcentered">
                <a class="navbar-brand" href="/">
                    <span><img src="/tdc_horizontal.png" alt="Logo" style="max-height: 40px; max-width: 250px;"></span>
                </a>
            </div>
            <div class="column is-4 has-text-right is-vcentered">
                <a href="https://arxiv.org/abs/2102.09548">
                    <span class="icon is-large">
                      <i class="fas fa-file-alt fa-3x"></i>
                    </span>
                </a>

                <a href="https://github.com/mims-harvard/TDC">
                    <span class="icon is-large">
                      <i class="fas fab fa-github fa-3x"></i>
                    </span>
                </a>

                <a href="https://twitter.com/ProjectTDC">
                    <span class="icon is-large">
                      <i class="fas fab fa-twitter fa-3x"></i>
                    </span>
                </a>

                <a href="https://join.slack.com/t/pytdc/shared_invite/zt-x0ujg5v6-zwtQZt83fhRdgrYjXRFz5g">
                    <span class="icon is-large">
                      <i class="fas fab fa-slack fa-3x"></i>
                    </span>
                </a>
            </div>
        </div>
        
    </div>
</footer> -->
    
    <script src="/assets/js/app.js" type="text/javascript"></script><!-- footer scripts --></body>
</html>

